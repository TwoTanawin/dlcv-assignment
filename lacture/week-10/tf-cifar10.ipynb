{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyPlS2NS1VCsub+l+sgrI9Y2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"xOn5AnwqOVVZ","executionInfo":{"status":"ok","timestamp":1696834718547,"user_tz":-420,"elapsed":2570,"user":{"displayName":"Tanawin Siriwan","userId":"16956349496620100462"}}},"outputs":[],"source":["from keras import layers\n","from keras import models\n","from keras.datasets import cifar10\n","from sklearn.preprocessing import LabelBinarizer"]},{"cell_type":"code","source":["model = models.Sequential()\n","model.add(layers.Conv2D(64, (5, 5), activation='relu', input_shape=(32, 32, 3)))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(64, (5, 5), activation='relu'))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Flatten())\n","model.add(layers.Dense(10, activation='softmax'))\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hvaxL-CsOsDc","executionInfo":{"status":"ok","timestamp":1696834724234,"user_tz":-420,"elapsed":3200,"user":{"displayName":"Tanawin Siriwan","userId":"16956349496620100462"}},"outputId":"21cda936-caa3-4175-c9ae-33e00a8cc116"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 28, 28, 64)        4864      \n","                                                                 \n"," max_pooling2d (MaxPooling2  (None, 14, 14, 64)        0         \n"," D)                                                              \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 10, 10, 64)        102464    \n","                                                                 \n"," max_pooling2d_1 (MaxPoolin  (None, 5, 5, 64)          0         \n"," g2D)                                                            \n","                                                                 \n"," flatten (Flatten)           (None, 1600)              0         \n","                                                                 \n"," dense (Dense)               (None, 10)                16010     \n","                                                                 \n","=================================================================\n","Total params: 123338 (481.79 KB)\n","Trainable params: 123338 (481.79 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["print(\"[INFO] loading CIFAR-10 data...\")\n","((trainX, trainY), (testX, testY)) = cifar10.load_data()\n","trainX = trainX.astype(\"float\") / 255.0\n","testX = testX.astype(\"float\") / 255.0\n","lb = LabelBinarizer()\n","trainY = lb.fit_transform(trainY)\n","testY = lb.transform(testY)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yxbOZDSTOw_s","executionInfo":{"status":"ok","timestamp":1696834744886,"user_tz":-420,"elapsed":7066,"user":{"displayName":"Tanawin Siriwan","userId":"16956349496620100462"}},"outputId":"f7efa959-91d5-4061-b2f9-3fc698165e7c"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO] loading CIFAR-10 data...\n","Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170498071/170498071 [==============================] - 4s 0us/step\n"]}]},{"cell_type":"code","source":["# initialize the label names for the CIFAR-10 dataset\n","labelNames = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\",\n","\"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n","\n","model.compile(optimizer='Adam',\n","loss='categorical_crossentropy',\n","metrics=['accuracy'])\n","\n","H = model.fit(trainX, trainY, validation_data=(testX, testY),\n","batch_size=250, epochs=100, verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"43jjEJj-O1KY","executionInfo":{"status":"ok","timestamp":1696834978725,"user_tz":-420,"elapsed":203882,"user":{"displayName":"Tanawin Siriwan","userId":"16956349496620100462"}},"outputId":"57a2fca5-3996-425b-962b-69c4476a9464"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","200/200 [==============================] - 13s 12ms/step - loss: 1.7371 - accuracy: 0.3711 - val_loss: 1.4610 - val_accuracy: 0.4769\n","Epoch 2/100\n","200/200 [==============================] - 2s 9ms/step - loss: 1.3845 - accuracy: 0.5075 - val_loss: 1.3068 - val_accuracy: 0.5387\n","Epoch 3/100\n","200/200 [==============================] - 2s 9ms/step - loss: 1.2581 - accuracy: 0.5576 - val_loss: 1.2115 - val_accuracy: 0.5720\n","Epoch 4/100\n","200/200 [==============================] - 2s 9ms/step - loss: 1.1672 - accuracy: 0.5917 - val_loss: 1.1696 - val_accuracy: 0.5902\n","Epoch 5/100\n","200/200 [==============================] - 2s 9ms/step - loss: 1.1138 - accuracy: 0.6133 - val_loss: 1.0951 - val_accuracy: 0.6192\n","Epoch 6/100\n","200/200 [==============================] - 2s 9ms/step - loss: 1.0660 - accuracy: 0.6307 - val_loss: 1.0570 - val_accuracy: 0.6373\n","Epoch 7/100\n","200/200 [==============================] - 2s 9ms/step - loss: 1.0273 - accuracy: 0.6468 - val_loss: 1.0424 - val_accuracy: 0.6380\n","Epoch 8/100\n","200/200 [==============================] - 2s 9ms/step - loss: 0.9943 - accuracy: 0.6591 - val_loss: 1.0068 - val_accuracy: 0.6526\n","Epoch 9/100\n","200/200 [==============================] - 2s 9ms/step - loss: 0.9604 - accuracy: 0.6690 - val_loss: 1.0522 - val_accuracy: 0.6378\n","Epoch 10/100\n","200/200 [==============================] - 2s 9ms/step - loss: 0.9378 - accuracy: 0.6786 - val_loss: 0.9885 - val_accuracy: 0.6605\n","Epoch 11/100\n","200/200 [==============================] - 2s 9ms/step - loss: 0.9100 - accuracy: 0.6873 - val_loss: 0.9796 - val_accuracy: 0.6632\n","Epoch 12/100\n","200/200 [==============================] - 2s 9ms/step - loss: 0.8833 - accuracy: 0.6954 - val_loss: 1.0347 - val_accuracy: 0.6398\n","Epoch 13/100\n","200/200 [==============================] - 2s 9ms/step - loss: 0.8633 - accuracy: 0.7024 - val_loss: 0.9541 - val_accuracy: 0.6761\n","Epoch 14/100\n","200/200 [==============================] - 2s 9ms/step - loss: 0.8420 - accuracy: 0.7122 - val_loss: 0.9639 - val_accuracy: 0.6705\n","Epoch 15/100\n","200/200 [==============================] - 2s 9ms/step - loss: 0.8342 - accuracy: 0.7141 - val_loss: 0.9481 - val_accuracy: 0.6766\n","Epoch 16/100\n","200/200 [==============================] - 2s 9ms/step - loss: 0.8106 - accuracy: 0.7216 - val_loss: 0.9468 - val_accuracy: 0.6791\n","Epoch 17/100\n","200/200 [==============================] - 2s 9ms/step - loss: 0.7918 - accuracy: 0.7281 - val_loss: 0.9340 - val_accuracy: 0.6815\n","Epoch 18/100\n","200/200 [==============================] - 2s 9ms/step - loss: 0.7887 - accuracy: 0.7294 - val_loss: 0.9537 - val_accuracy: 0.6808\n","Epoch 19/100\n","200/200 [==============================] - 2s 9ms/step - loss: 0.7631 - accuracy: 0.7366 - val_loss: 0.9089 - val_accuracy: 0.6970\n","Epoch 20/100\n","200/200 [==============================] - 2s 9ms/step - loss: 0.7527 - accuracy: 0.7412 - val_loss: 0.9254 - val_accuracy: 0.6859\n","Epoch 21/100\n","200/200 [==============================] - 2s 9ms/step - loss: 0.7432 - accuracy: 0.7437 - val_loss: 0.9815 - val_accuracy: 0.6643\n","Epoch 22/100\n","200/200 [==============================] - 2s 9ms/step - loss: 0.7366 - accuracy: 0.7462 - val_loss: 0.9278 - val_accuracy: 0.6860\n","Epoch 23/100\n","200/200 [==============================] - 2s 9ms/step - loss: 0.7150 - accuracy: 0.7536 - val_loss: 0.9048 - val_accuracy: 0.6990\n","Epoch 24/100\n","200/200 [==============================] - 2s 9ms/step - loss: 0.7058 - accuracy: 0.7584 - val_loss: 0.9101 - val_accuracy: 0.6922\n","Epoch 25/100\n","200/200 [==============================] - 2s 9ms/step - loss: 0.6974 - accuracy: 0.7603 - val_loss: 0.9502 - val_accuracy: 0.6851\n","Epoch 26/100\n","200/200 [==============================] - 2s 9ms/step - loss: 0.6890 - accuracy: 0.7631 - val_loss: 0.9406 - val_accuracy: 0.6875\n","Epoch 27/100\n","200/200 [==============================] - 2s 9ms/step - loss: 0.6747 - accuracy: 0.7667 - val_loss: 0.9209 - val_accuracy: 0.6953\n","Epoch 28/100\n","200/200 [==============================] - 2s 9ms/step - loss: 0.6626 - accuracy: 0.7715 - val_loss: 0.9152 - val_accuracy: 0.6987\n","Epoch 29/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.6522 - accuracy: 0.7766 - val_loss: 0.9058 - val_accuracy: 0.6966\n","Epoch 30/100\n","200/200 [==============================] - 2s 9ms/step - loss: 0.6416 - accuracy: 0.7809 - val_loss: 0.9133 - val_accuracy: 0.6918\n","Epoch 31/100\n","200/200 [==============================] - 2s 9ms/step - loss: 0.6291 - accuracy: 0.7839 - val_loss: 0.9453 - val_accuracy: 0.6919\n","Epoch 32/100\n","200/200 [==============================] - 2s 9ms/step - loss: 0.6160 - accuracy: 0.7898 - val_loss: 0.9053 - val_accuracy: 0.7041\n","Epoch 33/100\n","200/200 [==============================] - 2s 9ms/step - loss: 0.6081 - accuracy: 0.7927 - val_loss: 0.9152 - val_accuracy: 0.7012\n","Epoch 34/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.6039 - accuracy: 0.7954 - val_loss: 0.8998 - val_accuracy: 0.7053\n","Epoch 35/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.5930 - accuracy: 0.7968 - val_loss: 0.9103 - val_accuracy: 0.6982\n","Epoch 36/100\n","200/200 [==============================] - 2s 9ms/step - loss: 0.5864 - accuracy: 0.7988 - val_loss: 0.9450 - val_accuracy: 0.6950\n","Epoch 37/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.5790 - accuracy: 0.8014 - val_loss: 0.9228 - val_accuracy: 0.7009\n","Epoch 38/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.5683 - accuracy: 0.8054 - val_loss: 0.9140 - val_accuracy: 0.7055\n","Epoch 39/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.5531 - accuracy: 0.8091 - val_loss: 0.9315 - val_accuracy: 0.6986\n","Epoch 40/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.5536 - accuracy: 0.8120 - val_loss: 0.9223 - val_accuracy: 0.7057\n","Epoch 41/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.5443 - accuracy: 0.8135 - val_loss: 0.9360 - val_accuracy: 0.7025\n","Epoch 42/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.5384 - accuracy: 0.8162 - val_loss: 0.9285 - val_accuracy: 0.6997\n","Epoch 43/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.5287 - accuracy: 0.8202 - val_loss: 0.9531 - val_accuracy: 0.6949\n","Epoch 44/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.5166 - accuracy: 0.8233 - val_loss: 0.9550 - val_accuracy: 0.7016\n","Epoch 45/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.5165 - accuracy: 0.8220 - val_loss: 0.9565 - val_accuracy: 0.6959\n","Epoch 46/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.5094 - accuracy: 0.8261 - val_loss: 0.9634 - val_accuracy: 0.6997\n","Epoch 47/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.4989 - accuracy: 0.8289 - val_loss: 1.0092 - val_accuracy: 0.6858\n","Epoch 48/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.4947 - accuracy: 0.8307 - val_loss: 0.9773 - val_accuracy: 0.6943\n","Epoch 49/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.4774 - accuracy: 0.8356 - val_loss: 0.9555 - val_accuracy: 0.7043\n","Epoch 50/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.4697 - accuracy: 0.8396 - val_loss: 0.9912 - val_accuracy: 0.6967\n","Epoch 51/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.4623 - accuracy: 0.8415 - val_loss: 0.9865 - val_accuracy: 0.6973\n","Epoch 52/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.4646 - accuracy: 0.8391 - val_loss: 0.9789 - val_accuracy: 0.6976\n","Epoch 53/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.4483 - accuracy: 0.8466 - val_loss: 1.0189 - val_accuracy: 0.6984\n","Epoch 54/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.4433 - accuracy: 0.8494 - val_loss: 1.0550 - val_accuracy: 0.6838\n","Epoch 55/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.4434 - accuracy: 0.8488 - val_loss: 1.0133 - val_accuracy: 0.6990\n","Epoch 56/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.4368 - accuracy: 0.8507 - val_loss: 1.0336 - val_accuracy: 0.6970\n","Epoch 57/100\n","200/200 [==============================] - 2s 9ms/step - loss: 0.4294 - accuracy: 0.8525 - val_loss: 1.0273 - val_accuracy: 0.6988\n","Epoch 58/100\n","200/200 [==============================] - 2s 9ms/step - loss: 0.4176 - accuracy: 0.8567 - val_loss: 1.0326 - val_accuracy: 0.6968\n","Epoch 59/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.4141 - accuracy: 0.8581 - val_loss: 1.0481 - val_accuracy: 0.6976\n","Epoch 60/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.4032 - accuracy: 0.8616 - val_loss: 1.0487 - val_accuracy: 0.6959\n","Epoch 61/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.3997 - accuracy: 0.8638 - val_loss: 1.0711 - val_accuracy: 0.6907\n","Epoch 62/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.3847 - accuracy: 0.8698 - val_loss: 1.0662 - val_accuracy: 0.6999\n","Epoch 63/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.3864 - accuracy: 0.8699 - val_loss: 1.0763 - val_accuracy: 0.6906\n","Epoch 64/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.3776 - accuracy: 0.8714 - val_loss: 1.0920 - val_accuracy: 0.6910\n","Epoch 65/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.3828 - accuracy: 0.8687 - val_loss: 1.1149 - val_accuracy: 0.6893\n","Epoch 66/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.3682 - accuracy: 0.8738 - val_loss: 1.1432 - val_accuracy: 0.6913\n","Epoch 67/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.3590 - accuracy: 0.8781 - val_loss: 1.1163 - val_accuracy: 0.6920\n","Epoch 68/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.3597 - accuracy: 0.8759 - val_loss: 1.1162 - val_accuracy: 0.6938\n","Epoch 69/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.3483 - accuracy: 0.8828 - val_loss: 1.1208 - val_accuracy: 0.6939\n","Epoch 70/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.3481 - accuracy: 0.8807 - val_loss: 1.1442 - val_accuracy: 0.6962\n","Epoch 71/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.3328 - accuracy: 0.8871 - val_loss: 1.1544 - val_accuracy: 0.6913\n","Epoch 72/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.3355 - accuracy: 0.8856 - val_loss: 1.1821 - val_accuracy: 0.6888\n","Epoch 73/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.3293 - accuracy: 0.8873 - val_loss: 1.1863 - val_accuracy: 0.6918\n","Epoch 74/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.3277 - accuracy: 0.8874 - val_loss: 1.1868 - val_accuracy: 0.6948\n","Epoch 75/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.3170 - accuracy: 0.8923 - val_loss: 1.1988 - val_accuracy: 0.6897\n","Epoch 76/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.2984 - accuracy: 0.9013 - val_loss: 1.1917 - val_accuracy: 0.6928\n","Epoch 77/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.2967 - accuracy: 0.9003 - val_loss: 1.2274 - val_accuracy: 0.6866\n","Epoch 78/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.2950 - accuracy: 0.8997 - val_loss: 1.2269 - val_accuracy: 0.6949\n","Epoch 79/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.2993 - accuracy: 0.8970 - val_loss: 1.2313 - val_accuracy: 0.6917\n","Epoch 80/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.2866 - accuracy: 0.9027 - val_loss: 1.2537 - val_accuracy: 0.6892\n","Epoch 81/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.2856 - accuracy: 0.9034 - val_loss: 1.2692 - val_accuracy: 0.6877\n","Epoch 82/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.2745 - accuracy: 0.9064 - val_loss: 1.2917 - val_accuracy: 0.6882\n","Epoch 83/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.2719 - accuracy: 0.9089 - val_loss: 1.3093 - val_accuracy: 0.6829\n","Epoch 84/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.2632 - accuracy: 0.9111 - val_loss: 1.2906 - val_accuracy: 0.6883\n","Epoch 85/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.2633 - accuracy: 0.9117 - val_loss: 1.3532 - val_accuracy: 0.6880\n","Epoch 86/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.2624 - accuracy: 0.9109 - val_loss: 1.3295 - val_accuracy: 0.6876\n","Epoch 87/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.2489 - accuracy: 0.9164 - val_loss: 1.3560 - val_accuracy: 0.6839\n","Epoch 88/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.2474 - accuracy: 0.9179 - val_loss: 1.3293 - val_accuracy: 0.6894\n","Epoch 89/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.2446 - accuracy: 0.9183 - val_loss: 1.3911 - val_accuracy: 0.6778\n","Epoch 90/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.2321 - accuracy: 0.9232 - val_loss: 1.3999 - val_accuracy: 0.6809\n","Epoch 91/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.2368 - accuracy: 0.9202 - val_loss: 1.3998 - val_accuracy: 0.6878\n","Epoch 92/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.2293 - accuracy: 0.9239 - val_loss: 1.4096 - val_accuracy: 0.6834\n","Epoch 93/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.2250 - accuracy: 0.9246 - val_loss: 1.4510 - val_accuracy: 0.6849\n","Epoch 94/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.2182 - accuracy: 0.9282 - val_loss: 1.4403 - val_accuracy: 0.6831\n","Epoch 95/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.2115 - accuracy: 0.9300 - val_loss: 1.4523 - val_accuracy: 0.6897\n","Epoch 96/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.2133 - accuracy: 0.9284 - val_loss: 1.4534 - val_accuracy: 0.6883\n","Epoch 97/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.2040 - accuracy: 0.9323 - val_loss: 1.4749 - val_accuracy: 0.6862\n","Epoch 98/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.2031 - accuracy: 0.9335 - val_loss: 1.4857 - val_accuracy: 0.6878\n","Epoch 99/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.2020 - accuracy: 0.9333 - val_loss: 1.5290 - val_accuracy: 0.6849\n","Epoch 100/100\n","200/200 [==============================] - 2s 10ms/step - loss: 0.1934 - accuracy: 0.9361 - val_loss: 1.5408 - val_accuracy: 0.6794\n"]}]}]}