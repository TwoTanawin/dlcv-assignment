{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"V100","authorship_tag":"ABX9TyP5zCq954c2Y+15QEFVT01K"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FtTb3UNVDHgH","executionInfo":{"status":"ok","timestamp":1700374799212,"user_tz":-420,"elapsed":10,"user":{"displayName":"Tanawin Siriwan","userId":"08216138066220731432"}},"outputId":"13de6c5c-0230-4fde-f01f-b4336f0c8acb"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Nov 19 06:19:58 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   34C    P0    23W / 300W |      0MiB / 16384MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mRggBw1TDD-1","executionInfo":{"status":"ok","timestamp":1700374804338,"user_tz":-420,"elapsed":5130,"user":{"displayName":"Tanawin Siriwan","userId":"08216138066220731432"}},"outputId":"5ba655a9-55b8-4fe3-8925-d4ea0d85968a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorboardX\n","  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/101.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.23.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (23.2)\n","Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n","Installing collected packages: tensorboardX\n","Successfully installed tensorboardX-2.6.2.2\n"]}],"source":["!pip install tensorboardX"]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import errno\n","import torchvision.utils as vutils\n","from tensorboardX import SummaryWriter\n","from IPython import display\n","from matplotlib import pyplot as plt\n","import torch"],"metadata":{"id":"oQi540ajDH1S","executionInfo":{"status":"ok","timestamp":1700374809473,"user_tz":-420,"elapsed":5137,"user":{"displayName":"Tanawin Siriwan","userId":"08216138066220731432"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import errno\n","import torchvision.utils as vutils\n","from tensorboardX import SummaryWriter\n","from IPython import display\n","from matplotlib import pyplot as plt\n","import torch\n","\n","'''\n","    TensorBoard Data will be stored in './runs' path\n","'''\n","\n","\n","class Logger:\n","\n","    def __init__(self, model_name, data_name):\n","        self.model_name = model_name\n","        self.data_name = data_name\n","\n","        self.comment = '{}_{}'.format(model_name, data_name)\n","        self.data_subdir = '{}/{}'.format(model_name, data_name)\n","\n","        # TensorBoard\n","        self.writer = SummaryWriter(comment=self.comment)\n","\n","    def log(self, d_error, g_error, epoch, n_batch, num_batches):\n","\n","        # var_class = torch.autograd.variable.Variable\n","        if isinstance(d_error, torch.autograd.Variable):\n","            d_error = d_error.data.cpu().numpy()\n","        if isinstance(g_error, torch.autograd.Variable):\n","            g_error = g_error.data.cpu().numpy()\n","\n","        step = Logger._step(epoch, n_batch, num_batches)\n","        self.writer.add_scalar(\n","            '{}/D_error'.format(self.comment), d_error, step)\n","        self.writer.add_scalar(\n","            '{}/G_error'.format(self.comment), g_error, step)\n","\n","    def log_images(self, images, num_images, epoch, n_batch, num_batches, format='NCHW', normalize=True):\n","        '''\n","        input images are expected in format (NCHW)\n","        '''\n","        if type(images) == np.ndarray:\n","            images = torch.from_numpy(images)\n","\n","        if format=='NHWC':\n","            images = images.transpose(1,3)\n","\n","\n","        step = Logger._step(epoch, n_batch, num_batches)\n","        img_name = '{}/images{}'.format(self.comment, '')\n","\n","        # Make horizontal grid from image tensor\n","        horizontal_grid = vutils.make_grid(\n","            images, normalize=normalize, scale_each=True)\n","        # Make vertical grid from image tensor\n","        nrows = int(np.sqrt(num_images))\n","        grid = vutils.make_grid(\n","            images, nrow=nrows, normalize=True, scale_each=True)\n","\n","        # Add horizontal images to tensorboard\n","        self.writer.add_image(img_name, horizontal_grid, step)\n","\n","        # Save plots\n","        self.save_torch_images(horizontal_grid, grid, epoch, n_batch)\n","\n","    def save_torch_images(self, horizontal_grid, grid, epoch, n_batch, plot_horizontal=True):\n","        out_dir = './data/images/{}'.format(self.data_subdir)\n","        Logger._make_dir(out_dir)\n","\n","        # Plot and save horizontal\n","        fig = plt.figure(figsize=(16, 16))\n","        plt.imshow(np.moveaxis(horizontal_grid.numpy(), 0, -1))\n","        plt.axis('off')\n","        if plot_horizontal:\n","            display.display(plt.gcf())\n","        self._save_images(fig, epoch, n_batch, 'hori')\n","        plt.close()\n","\n","        # Save squared\n","        fig = plt.figure()\n","        plt.imshow(np.moveaxis(grid.numpy(), 0, -1))\n","        plt.axis('off')\n","        self._save_images(fig, epoch, n_batch)\n","        plt.close()\n","\n","    def _save_images(self, fig, epoch, n_batch, comment=''):\n","        out_dir = './data/images/{}'.format(self.data_subdir)\n","        Logger._make_dir(out_dir)\n","        fig.savefig('{}/{}_epoch_{}_batch_{}.png'.format(out_dir,\n","                                                         comment, epoch, n_batch))\n","\n","    def display_status(self, epoch, num_epochs, n_batch, num_batches, d_error, g_error, d_pred_real, d_pred_fake):\n","\n","        # var_class = torch.autograd.variable.Variable\n","        if isinstance(d_error, torch.autograd.Variable):\n","            d_error = d_error.data.cpu().numpy()\n","        if isinstance(g_error, torch.autograd.Variable):\n","            g_error = g_error.data.cpu().numpy()\n","        if isinstance(d_pred_real, torch.autograd.Variable):\n","            d_pred_real = d_pred_real.data\n","        if isinstance(d_pred_fake, torch.autograd.Variable):\n","            d_pred_fake = d_pred_fake.data\n","\n","\n","        print('Epoch: [{}/{}], Batch Num: [{}/{}]'.format(\n","            epoch,num_epochs, n_batch, num_batches)\n","             )\n","        print('Discriminator Loss: {:.4f}, Generator Loss: {:.4f}'.format(d_error, g_error))\n","        print('D(x): {:.4f}, D(G(z)): {:.4f}'.format(d_pred_real.mean(), d_pred_fake.mean()))\n","\n","    def save_models(self, generator, discriminator, epoch):\n","        out_dir = './data/models/{}'.format(self.data_subdir)\n","        Logger._make_dir(out_dir)\n","        torch.save(generator.state_dict(),\n","                   '{}/G_epoch_{}'.format(out_dir, epoch))\n","        torch.save(discriminator.state_dict(),\n","                   '{}/D_epoch_{}'.format(out_dir, epoch))\n","\n","    def close(self):\n","        self.writer.close()\n","\n","    # Private Functionality\n","\n","    @staticmethod\n","    def _step(epoch, n_batch, num_batches):\n","        return epoch * num_batches + n_batch\n","\n","    @staticmethod\n","    def _make_dir(directory):\n","        try:\n","            os.makedirs(directory)\n","        except OSError as e:\n","            if e.errno != errno.EEXIST:\n","                raise"],"metadata":{"id":"k7ZBA-H2G9D_","executionInfo":{"status":"ok","timestamp":1700374810085,"user_tz":-420,"elapsed":9,"user":{"displayName":"Tanawin Siriwan","userId":"08216138066220731432"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import torch\n","from torch import nn, optim\n","from torchvision import transforms, datasets\n","\n","DATA_FOLDER = './torch_data/VGAN/MNIST'\n","def mnist_data():\n","    compose = transforms.Compose(\n","        [transforms.ToTensor(),\n","         transforms.Normalize([0.5], [0.5])\n","        ])\n","    out_dir = '{}/dataset'.format(DATA_FOLDER)\n","    return datasets.MNIST(root=out_dir, train=True, transform=compose, download=True)\n","\n","# Load Dataset and attach a DataLoader\n","\n","data = mnist_data()\n","data_loader = torch.utils.data.DataLoader(data, batch_size=100, shuffle=True)\n","num_batches = len(data_loader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HvW1ocD5Ha3O","executionInfo":{"status":"ok","timestamp":1700374810635,"user_tz":-420,"elapsed":558,"user":{"displayName":"Tanawin Siriwan","userId":"08216138066220731432"}},"outputId":"72b12773-1916-42b3-a01f-1f346f4d45bf"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./torch_data/VGAN/MNIST/dataset/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9912422/9912422 [00:00<00:00, 265371234.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./torch_data/VGAN/MNIST/dataset/MNIST/raw/train-images-idx3-ubyte.gz to ./torch_data/VGAN/MNIST/dataset/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./torch_data/VGAN/MNIST/dataset/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28881/28881 [00:00<00:00, 27789789.82it/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting ./torch_data/VGAN/MNIST/dataset/MNIST/raw/train-labels-idx1-ubyte.gz to ./torch_data/VGAN/MNIST/dataset/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./torch_data/VGAN/MNIST/dataset/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1648877/1648877 [00:00<00:00, 63259925.88it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./torch_data/VGAN/MNIST/dataset/MNIST/raw/t10k-images-idx3-ubyte.gz to ./torch_data/VGAN/MNIST/dataset/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./torch_data/VGAN/MNIST/dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4542/4542 [00:00<00:00, 4274294.09it/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting ./torch_data/VGAN/MNIST/dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./torch_data/VGAN/MNIST/dataset/MNIST/raw\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["class GeneratorNet(torch.nn.Module):\n","    \"\"\"\n","    A three hidden-layer generative neural network\n","    \"\"\"\n","    def __init__(self):\n","        super(GeneratorNet, self).__init__()\n","        n_features = 100\n","        n_out = 784\n","\n","        self.hidden0 = nn.Sequential(\n","            nn.Linear(n_features, 256),\n","            nn.LeakyReLU(0.2)\n","        )\n","        self.hidden1 = nn.Sequential(\n","            nn.Linear(256, 512),\n","            nn.LeakyReLU(0.2)\n","        )\n","        self.hidden2 = nn.Sequential(\n","            nn.Linear(512, 1024),\n","            nn.LeakyReLU(0.2)\n","        )\n","\n","        self.out = nn.Sequential(\n","            nn.Linear(1024, n_out),\n","            nn.Tanh()\n","        )\n","\n","    def forward(self, x):\n","        x = self.hidden0(x)\n","        x = self.hidden1(x)\n","        x = self.hidden2(x)\n","        x = self.out(x)\n","        return x\n","\n","# Function to create noise samples for the generator's input\n","\n","def noise(size):\n","    n = torch.randn(size, 100)\n","    if torch.cuda.is_available(): return n.cuda()\n","    return n"],"metadata":{"id":"lg5IND7vHCH5","executionInfo":{"status":"ok","timestamp":1700374810635,"user_tz":-420,"elapsed":5,"user":{"displayName":"Tanawin Siriwan","userId":"08216138066220731432"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["class DiscriminatorNet(torch.nn.Module):\n","    \"\"\"\n","    A three hidden-layer discriminative neural network\n","    \"\"\"\n","    def __init__(self):\n","        super(DiscriminatorNet, self).__init__()\n","        n_features = 784\n","        n_out = 1\n","\n","        self.hidden0 = nn.Sequential(\n","            nn.Linear(n_features, 1024),\n","            nn.LeakyReLU(0.2),\n","            nn.Dropout(0.3)\n","        )\n","        self.hidden1 = nn.Sequential(\n","            nn.Linear(1024, 512),\n","            nn.LeakyReLU(0.2),\n","            nn.Dropout(0.3)\n","        )\n","        self.hidden2 = nn.Sequential(\n","            nn.Linear(512, 256),\n","            nn.LeakyReLU(0.2),\n","            nn.Dropout(0.3)\n","        )\n","        self.out = nn.Sequential(\n","            torch.nn.Linear(256, n_out),\n","            torch.nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        x = self.hidden0(x)\n","        x = self.hidden1(x)\n","        x = self.hidden2(x)\n","        x = self.out(x)\n","        return x\n","\n","def images_to_vectors(images):\n","    return images.view(images.size(0), 784)\n","\n","def vectors_to_images(vectors):\n","    return vectors.view(vectors.size(0), 1, 28, 28)"],"metadata":{"id":"_nHlrFKvHDl9","executionInfo":{"status":"ok","timestamp":1700374810636,"user_tz":-420,"elapsed":6,"user":{"displayName":"Tanawin Siriwan","userId":"08216138066220731432"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["discriminator = DiscriminatorNet()\n","generator = GeneratorNet()\n","\n","if torch.cuda.is_available():\n","    discriminator.cuda()\n","    generator.cuda()"],"metadata":{"id":"n8AuzHPpHO9Z","executionInfo":{"status":"ok","timestamp":1700374816825,"user_tz":-420,"elapsed":6194,"user":{"displayName":"Tanawin Siriwan","userId":"08216138066220731432"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Optimizers\n","\n","d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002)\n","g_optimizer = optim.Adam(generator.parameters(), lr=0.0002)\n","\n","# Loss function\n","\n","loss = nn.BCELoss()\n","\n","# How many epochs to train for\n","\n","num_epochs = 200\n","\n","# Number of steps to apply to the discriminator for each step of the generator (1 in Goodfellow et al.)\n","\n","d_steps = 1"],"metadata":{"id":"5ifSX008HUVQ","executionInfo":{"status":"ok","timestamp":1700374816825,"user_tz":-420,"elapsed":3,"user":{"displayName":"Tanawin Siriwan","userId":"08216138066220731432"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def real_data_target(size):\n","    '''\n","    Tensor containing ones, with shape = size\n","    '''\n","    data = torch.ones(size, 1)\n","    if torch.cuda.is_available(): return data.cuda()\n","    return data\n","\n","def fake_data_target(size):\n","    '''\n","    Tensor containing zeros, with shape = size\n","    '''\n","    data = torch.zeros(size, 1)\n","    if torch.cuda.is_available(): return data.cuda()\n","    return data"],"metadata":{"id":"28Yuqro6HVok","executionInfo":{"status":"ok","timestamp":1700374816825,"user_tz":-420,"elapsed":2,"user":{"displayName":"Tanawin Siriwan","userId":"08216138066220731432"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def train_discriminator(optimizer, real_data, fake_data):\n","    # Reset gradients\n","    optimizer.zero_grad()\n","\n","    # Propagate real data\n","    prediction_real = discriminator(real_data)\n","    error_real = loss(prediction_real, real_data_target(real_data.size(0)))\n","    error_real.backward()\n","\n","    # Propagate fake data\n","    prediction_fake = discriminator(fake_data)\n","    error_fake = loss(prediction_fake, fake_data_target(real_data.size(0)))\n","    error_fake.backward()\n","\n","    # Take a step\n","    optimizer.step()\n","\n","    # Return error\n","    return error_real + error_fake, prediction_real, prediction_fake"],"metadata":{"id":"XW9ylOMsHcDD","executionInfo":{"status":"ok","timestamp":1700374816826,"user_tz":-420,"elapsed":3,"user":{"displayName":"Tanawin Siriwan","userId":"08216138066220731432"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["def train_generator(optimizer, fake_data):\n","    # Reset gradients\n","    optimizer.zero_grad()\n","\n","    # Propagate the fake data through the discriminator and backpropagate.\n","    # Note that since we want the generator to output something that gets\n","    # the discriminator to output a 1, we use the real data target here.\n","    prediction = discriminator(fake_data)\n","    error = loss(prediction, real_data_target(prediction.size(0)))\n","    error.backward()\n","\n","    # Update weights with gradients\n","    optimizer.step()\n","\n","    # Return error\n","    return error"],"metadata":{"id":"qKtwJ6LZHgWF","executionInfo":{"status":"ok","timestamp":1700374816826,"user_tz":-420,"elapsed":3,"user":{"displayName":"Tanawin Siriwan","userId":"08216138066220731432"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["DATA_FOLDER = './torch_data/DCGAN/CIFAR'\n","\n","def cifar_data():\n","    compose = transforms.Compose(\n","        [\n","            transforms.Resize(64),\n","            transforms.ToTensor(),\n","            transforms.Normalize((.5, .5, .5), (.5, .5, .5))\n","        ])\n","    out_dir = '{}/dataset'.format(DATA_FOLDER)\n","    return datasets.CIFAR10(root=out_dir, train=True, transform=compose, download=True)\n","\n","data = cifar_data()\n","batch_size = 1024\n","data_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True)\n","num_batches = len(data_loader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Na7L9pcSHik8","executionInfo":{"status":"ok","timestamp":1700374825600,"user_tz":-420,"elapsed":8777,"user":{"displayName":"Tanawin Siriwan","userId":"08216138066220731432"}},"outputId":"278d7cdc-1ff8-4257-b899-0f2dd63e5bb8"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./torch_data/DCGAN/CIFAR/dataset/cifar-10-python.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 170498071/170498071 [00:05<00:00, 29318319.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./torch_data/DCGAN/CIFAR/dataset/cifar-10-python.tar.gz to ./torch_data/DCGAN/CIFAR/dataset\n"]}]},{"cell_type":"code","source":["class DiscriminativeNet(torch.nn.Module):\n","\n","    def __init__(self):\n","        super(DiscriminativeNet, self).__init__()\n","\n","        self.conv1 = nn.Sequential(\n","            nn.Conv2d(\n","                in_channels=3, out_channels=128, kernel_size=4,\n","                stride=2, padding=1, bias=False\n","            ),\n","            nn.LeakyReLU(0.2, inplace=True)\n","        )\n","        self.conv2 = nn.Sequential(\n","            nn.Conv2d(\n","                in_channels=128, out_channels=256, kernel_size=4,\n","                stride=2, padding=1, bias=False\n","            ),\n","            nn.BatchNorm2d(256),\n","            nn.LeakyReLU(0.2, inplace=True)\n","        )\n","        self.conv3 = nn.Sequential(\n","            nn.Conv2d(\n","                in_channels=256, out_channels=512, kernel_size=4,\n","                stride=2, padding=1, bias=False\n","            ),\n","            nn.BatchNorm2d(512),\n","            nn.LeakyReLU(0.2, inplace=True)\n","        )\n","        self.conv4 = nn.Sequential(\n","            nn.Conv2d(\n","                in_channels=512, out_channels=1024, kernel_size=4,\n","                stride=2, padding=1, bias=False\n","            ),\n","            nn.BatchNorm2d(1024),\n","            nn.LeakyReLU(0.2, inplace=True)\n","        )\n","        self.out = nn.Sequential(\n","            nn.Linear(1024*4*4, 1),\n","            nn.Sigmoid(),\n","        )\n","\n","    def forward(self, x):\n","        # Convolutional layers\n","        x = self.conv1(x)\n","        x = self.conv2(x)\n","        x = self.conv3(x)\n","        x = self.conv4(x)\n","        # Flatten and apply sigmoid\n","        x = x.view(-1, 1024*4*4)\n","        x = self.out(x)\n","        return x"],"metadata":{"id":"0zN_SWTWHj67","executionInfo":{"status":"ok","timestamp":1700374825600,"user_tz":-420,"elapsed":9,"user":{"displayName":"Tanawin Siriwan","userId":"08216138066220731432"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["class GenerativeNet(torch.nn.Module):\n","\n","    def __init__(self):\n","        super(GenerativeNet, self).__init__()\n","\n","        self.linear = torch.nn.Linear(100, 1024*4*4)\n","\n","        self.conv1 = nn.Sequential(\n","            nn.ConvTranspose2d(\n","                in_channels=1024, out_channels=512, kernel_size=4,\n","                stride=2, padding=1, bias=False\n","            ),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(inplace=True)\n","        )\n","        self.conv2 = nn.Sequential(\n","            nn.ConvTranspose2d(\n","                in_channels=512, out_channels=256, kernel_size=4,\n","                stride=2, padding=1, bias=False\n","            ),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(inplace=True)\n","        )\n","        self.conv3 = nn.Sequential(\n","            nn.ConvTranspose2d(\n","                in_channels=256, out_channels=128, kernel_size=4,\n","                stride=2, padding=1, bias=False\n","            ),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(inplace=True)\n","        )\n","        self.conv4 = nn.Sequential(\n","            nn.ConvTranspose2d(\n","                in_channels=128, out_channels=3, kernel_size=4,\n","                stride=2, padding=1, bias=False\n","            )\n","        )\n","        self.out = torch.nn.Tanh()\n","\n","    def forward(self, x):\n","        # Project and reshape\n","        x = self.linear(x)\n","        x = x.view(x.shape[0], 1024, 4, 4)\n","        # Convolutional layers\n","        x = self.conv1(x)\n","        x = self.conv2(x)\n","        x = self.conv3(x)\n","        x = self.conv4(x)\n","        # Apply Tanh\n","        return self.out(x)\n"],"metadata":{"id":"jGg42_SGHlJW","executionInfo":{"status":"ok","timestamp":1700374825601,"user_tz":-420,"elapsed":10,"user":{"displayName":"Tanawin Siriwan","userId":"08216138066220731432"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# Custom weight initialization\n","\n","def init_weights(m):\n","    classname = m.__class__.__name__\n","    if classname.find('Conv') != -1 or classname.find('BatchNorm') != -1:\n","        m.weight.data.normal_(0.00, 0.02)\n","\n","# Instantiate networks\n","\n","generator = GenerativeNet()\n","generator.apply(init_weights)\n","discriminator = DiscriminativeNet()\n","discriminator.apply(init_weights)\n","\n","# Enable cuda if available\n","\n","if torch.cuda.is_available():\n","    generator.cuda()\n","    discriminator.cuda()"],"metadata":{"id":"ebzF1ijjHmkE","executionInfo":{"status":"ok","timestamp":1700374826205,"user_tz":-420,"elapsed":613,"user":{"displayName":"Tanawin Siriwan","userId":"08216138066220731432"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# Optimizers\n","\n","d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n","g_optimizer = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n","\n","# Loss function\n","\n","loss = nn.BCELoss()\n","\n","# Number of epochs of training\n","num_epochs = 30"],"metadata":{"id":"OFkbI29LHn6p","executionInfo":{"status":"ok","timestamp":1700374826205,"user_tz":-420,"elapsed":2,"user":{"displayName":"Tanawin Siriwan","userId":"08216138066220731432"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["num_test_samples = 16\n","test_noise = noise(num_test_samples)\n","\n","logger = Logger(model_name='DCGAN', data_name='CIFAR10')\n","\n","for epoch in range(num_epochs):\n","    for n_batch, (real_data,_) in enumerate(data_loader):\n","\n","        # Train Discriminator\n","\n","        if torch.cuda.is_available(): real_data = real_data.cuda()\n","        fake_data = generator(noise(real_data.size(0))).detach()\n","        d_error, d_pred_real, d_pred_fake = train_discriminator(d_optimizer,\n","                                                                real_data, fake_data)\n","\n","        # Train Generator\n","\n","        fake_data = generator(noise(real_batch.size(0)))\n","        g_error = train_generator(g_optimizer, fake_data)\n","\n","        # Log error and display progress\n","        logger.log(d_error, g_error, epoch, n_batch, num_batches)\n","        if (n_batch) % 100 == 0:\n","            display.clear_output(True)\n","            # Display Images\n","            test_images = generator(test_noise).data.cpu()\n","            logger.log_images(test_images, num_test_samples, epoch, n_batch, num_batches);\n","            # Display status Logs\n","            logger.display_status(\n","                epoch, num_epochs, n_batch, num_batches,\n","                d_error, g_error, d_pred_real, d_pred_fake\n","            )\n","\n","        # Save model checkpoints\n","        logger.save_models(generator, discriminator, epoch)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":245},"id":"ut17N5OcHp1C","executionInfo":{"status":"error","timestamp":1700374834742,"user_tz":-420,"elapsed":8539,"user":{"displayName":"Tanawin Siriwan","userId":"08216138066220731432"}},"outputId":"7299f943-ba6e-42c5-e33c-007165e91bd5"},"execution_count":18,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-e644a0745cd6>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Train Generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mfake_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mg_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'real_batch' is not defined"]}]}]}